â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              WANDB METRICS GUIDE - Complete Reference                â•‘
â•‘                  All Metrics, Charts, and F1 Score                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… NEW: F1 Score is now automatically logged every epoch!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š ALL METRICS LOGGED TO WANDB

PERFORMANCE METRICS (Main metrics to watch):
  âœ… metrics/mAP50           - Mean Average Precision @ 0.5 IoU
  âœ… metrics/mAP50-95         - Mean Average Precision @ 0.5:0.95 IoU
  âœ… metrics/precision        - Overall Precision
  âœ… metrics/recall           - Overall Recall
  âœ… metrics/f1_score         - F1 Score (NEW! Custom added)

TRAINING LOSSES:
  âœ… train/box_loss           - Bounding box regression loss
  âœ… train/cls_loss           - Classification loss
  âœ… train/dfl_loss           - Distribution focal loss

VALIDATION LOSSES:
  âœ… val/box_loss             - Validation box loss
  âœ… val/cls_loss             - Validation classification loss
  âœ… val/dfl_loss             - Validation DFL loss

LEARNING RATES:
  âœ… lr/pg0                   - Learning rate parameter group 0
  âœ… lr/pg1                   - Learning rate parameter group 1
  âœ… lr/pg2                   - Learning rate parameter group 2

TEST METRICS (After training):
  âœ… test/mAP50               - Test set mAP50
  âœ… test/mAP50-95            - Test set mAP50-95
  âœ… test/precision           - Test set Precision
  âœ… test/recall              - Test set Recall
  âœ… test/f1_score            - Test set F1 Score (NEW!)

PER-CLASS METRICS (NEW!):
  âœ… test/Buffalo_mAP50       - Buffalo mAP50
  âœ… test/Elephant_mAP50      - Elephant mAP50
  âœ… test/Kudu_mAP50          - Kudu mAP50
  âœ… test/Topi_mAP50          - Topi mAP50
  âœ… test/Warthog_mAP50       - Warthog mAP50
  âœ… test/Waterbuck_mAP50     - Waterbuck mAP50

SYSTEM METRICS:
  âœ… epoch                    - Current epoch number
  âœ… _timestamp               - Wall clock time

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ KEY METRICS EXPLAINED

ğŸ“ˆ mAP50 (Mean Average Precision @ IoU=0.5)
   What: Measures detection accuracy
   Range: 0.0 to 1.0 (higher is better)
   Target: > 0.5 (good), > 0.7 (excellent)
   
   How to interpret:
   - 0.65 = Model correctly detects 65% of animals
   - Primary metric for object detection
   - Most important single metric

ğŸ“‰ mAP50-95 (Mean Average Precision @ IoU=0.5:0.95)
   What: Stricter version of mAP50, averages IoU from 0.5 to 0.95
   Range: 0.0 to 1.0 (higher is better)
   Target: > 0.3 (good), > 0.5 (excellent)
   
   How to interpret:
   - More challenging than mAP50
   - Rewards precise bounding boxes
   - Used in competitions (e.g., COCO)

ğŸ¯ Precision
   What: Percentage of correct positive predictions
   Formula: TP / (TP + FP)
   Range: 0.0 to 1.0 (higher is better)
   Target: > 0.6 (good), > 0.8 (excellent)
   
   How to interpret:
   - 0.80 = 80% of detections are correct
   - High precision = few false positives
   - Important when false alarms are costly

ğŸ” Recall
   What: Percentage of actual objects detected
   Formula: TP / (TP + FN)
   Range: 0.0 to 1.0 (higher is better)
   Target: > 0.5 (good), > 0.7 (excellent)
   
   How to interpret:
   - 0.75 = Found 75% of all animals
   - High recall = few missed detections
   - Important when missing objects is costly

âš–ï¸ F1 Score (NEW!)
   What: Harmonic mean of Precision and Recall
   Formula: 2 * (Precision * Recall) / (Precision + Recall)
   Range: 0.0 to 1.0 (higher is better)
   Target: > 0.6 (good), > 0.75 (excellent)
   
   How to interpret:
   - Balances Precision and Recall
   - 0.70 = Good balance between finding objects and being accurate
   - Useful when you care about both metrics equally

ğŸ“¦ box_loss
   What: How well bounding boxes fit objects
   Range: Lower is better (typically 0.5-2.0 at start, <0.5 at end)
   
   How to interpret:
   - Should decrease over training
   - Plateau = boxes fitting well
   - Increase = overfitting or learning rate too high

ğŸ·ï¸ cls_loss
   What: How well model classifies objects
   Range: Lower is better
   
   How to interpret:
   - Should decrease over training
   - Low value = confident correct classifications

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’» HOW TO VIEW METRICS IN WANDB

STEP 1: Access Wandb Dashboard
   During training, you'll see:
     âœ“ Wandb initialized
       Project: yolov11-wildlife-detection
       Dashboard: https://wandb.ai/your-username/yolov11-wildlife-detection/runs/...
   
   Click that URL!

STEP 2: Navigate to Charts Tab
   â€¢ Click "Charts" or "Workspace" in the left sidebar
   â€¢ You'll see all metrics graphed in real-time

STEP 3: Find F1 Score
   â€¢ Look for chart titled "metrics/f1_score"
   â€¢ Or search for "f1" in the search box
   â€¢ Should appear alongside precision and recall

STEP 4: Customize Charts
   â€¢ Click "+ Add panel" to create custom charts
   â€¢ Select metrics to compare
   â€¢ Choose visualization type (line, bar, scatter)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š RECOMMENDED CHARTS TO CREATE

CHART 1: Performance Overview
  Metrics: mAP50, mAP50-95, F1 Score
  Type: Line chart
  Why: Track overall model performance

CHART 2: Precision vs Recall
  Metrics: precision, recall
  Type: Line chart
  Why: See trade-off between precision and recall

CHART 3: Training Losses
  Metrics: train/box_loss, train/cls_loss, train/dfl_loss
  Type: Line chart
  Why: Monitor training convergence

CHART 4: Validation Losses
  Metrics: val/box_loss, val/cls_loss
  Type: Line chart
  Why: Detect overfitting (if val loss increases)

CHART 5: Per-Class Performance
  Metrics: test/Buffalo_mAP50, test/Elephant_mAP50, ... (all 6 classes)
  Type: Bar chart
  Why: See which species are hard to detect

CHART 6: Learning Rates
  Metrics: lr/pg0, lr/pg1, lr/pg2
  Type: Line chart
  Why: Monitor learning rate schedule

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ HOW TO CREATE CUSTOM CHARTS

1. Go to your Wandb dashboard
2. Click "+ Add visualization" or "+ Add panel"
3. Select "Line Plot" or "Bar Chart"
4. Choose X-axis: "Step" or "epoch"
5. Choose Y-axis: Select your metric (e.g., "metrics/f1_score")
6. Add multiple Y-axes to compare metrics
7. Click "Save"

EXAMPLE: F1 Score Chart
  1. Click "+ Add visualization"
  2. Select "Line Plot"
  3. X-axis: "epoch"
  4. Y-axis: "metrics/f1_score"
  5. Add more: "metrics/precision", "metrics/recall"
  6. Title: "F1 Score and Components"
  7. Save!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ˆ EXAMPLE TRAINING PROGRESSION

Epoch 1:
  mAP50: 0.15 (low - just starting)
  Precision: 0.30
  Recall: 0.20
  F1 Score: 0.24

Epoch 10:
  mAP50: 0.45 (improving)
  Precision: 0.60
  Recall: 0.50
  F1 Score: 0.55

Epoch 25:
  mAP50: 0.62 (good)
  Precision: 0.75
  Recall: 0.68
  F1 Score: 0.71

Epoch 50:
  mAP50: 0.70 (excellent!)
  Precision: 0.82
  Recall: 0.75
  F1 Score: 0.78

This shows healthy improvement over training!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… WHAT TO LOOK FOR

GOOD SIGNS:
  âœ… mAP50 steadily increasing
  âœ… Losses steadily decreasing
  âœ… Precision and Recall both improving
  âœ… F1 Score increasing (balanced improvement)
  âœ… Val losses tracking train losses

BAD SIGNS:
  âŒ mAP50 plateauing too early (undertraining)
  âŒ Val loss increasing while train loss decreasing (overfitting)
  âŒ Precision high but recall low (missing many objects)
  âŒ Recall high but precision low (too many false positives)
  âŒ Losses oscillating wildly (learning rate too high)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”§ TROUBLESHOOTING WANDB

ISSUE: "I don't see any metrics"
SOLUTION:
  â€¢ Check Wandb initialization message during training
  â€¢ Make sure you didn't use --no-wandb flag
  â€¢ Refresh the dashboard page
  â€¢ Check you're looking at the right project/run

ISSUE: "I see some metrics but not F1 score"
SOLUTION:
  â€¢ Make sure you're using the updated train_vm.py
  â€¢ F1 score appears after first epoch completes
  â€¢ Look for "metrics/f1_score" in the search box
  â€¢ May need to refresh page

ISSUE: "Metrics stopped updating"
SOLUTION:
  â€¢ Check if training is still running
  â€¢ Refresh the page
  â€¢ Check internet connection
  â€¢ Training may have finished!

ISSUE: "Can't find my run"
SOLUTION:
  â€¢ Check project name: "yolov11-wildlife-detection"
  â€¢ Look in "Runs" tab
  â€¢ Search by run name or date
  â€¢ Check if you're logged into correct account

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ PRO TIPS

1. Compare Multiple Runs
   â€¢ Train with different hyperparameters
   â€¢ Select multiple runs in Wandb
   â€¢ Compare F1 scores side-by-side
   â€¢ Find best configuration

2. Use Wandb Reports
   â€¢ Create a report to share results
   â€¢ Include key charts and findings
   â€¢ Document your best model
   â€¢ Share with team

3. Set Up Alerts
   â€¢ Configure email alerts for milestones
   â€¢ Get notified when mAP50 > 0.7
   â€¢ Monitor training remotely

4. Log Custom Notes
   â€¢ Add notes to runs in Wandb
   â€¢ Document what worked/didn't work
   â€¢ Track experiment ideas

5. Use Tags
   â€¢ Tag runs with experiment types
   â€¢ "baseline", "with-augmentation", "fine-tuned"
   â€¢ Easy filtering later

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ” ACCESSING METRICS PROGRAMMATICALLY

In Wandb Dashboard:
  â€¢ Go to your run
  â€¢ Click "Overview" tab
  â€¢ Scroll down to "Summary" section
  â€¢ Shows final values of all metrics

Download Metrics CSV:
  â€¢ Click "Charts" tab
  â€¢ Click "..." on any chart
  â€¢ Select "Download CSV"
  â€¢ Get raw data for analysis

Using Wandb API (optional):
  import wandb
  api = wandb.Api()
  run = api.run("username/yolov11-wildlife-detection/run_id")
  metrics = run.history()
  print(metrics['metrics/f1_score'])

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š EXAMPLE WANDB DASHBOARD LAYOUT

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ mAP50 over time                                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚                                                    â•±â”€â”€â”€    â”‚   â”‚
â”‚ â”‚                                            â•±â”€â”€â”€â”€â”€â”€â•±        â”‚   â”‚
â”‚ â”‚                                    â•±â”€â”€â”€â”€â”€â”€â•±                â”‚   â”‚
â”‚ â”‚                            â•±â”€â”€â”€â”€â”€â”€â•±                        â”‚   â”‚
â”‚ â”‚                    â•±â”€â”€â”€â”€â”€â”€â•±                                â”‚   â”‚
â”‚ â”‚            â•±â”€â”€â”€â”€â”€â”€â•±                                        â”‚   â”‚
â”‚ â”‚    â•±â”€â”€â”€â”€â”€â”€â•±                                                â”‚   â”‚
â”‚ â”‚â”€â”€â”€â•±                                                        â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ F1 Score, Precision, Recall                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ â”€â”€ F1 Score                                                â”‚   â”‚
â”‚ â”‚ -- Precision                                               â”‚   â”‚
â”‚ â”‚ Â·Â· Recall                                                  â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Losses                                                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ â•²                                                          â”‚   â”‚
â”‚ â”‚  â•²                                                         â”‚   â”‚
â”‚ â”‚   â•²___                                                     â”‚   â”‚
â”‚ â”‚       â•²___                                                 â”‚   â”‚
â”‚ â”‚           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… VERIFICATION

To verify F1 score is being logged:

1. Start training:
   python train_vm.py --epochs 50

2. Check training output:
   âœ“ Custom F1 score logging callback added

3. Wait for first epoch to complete

4. Go to Wandb dashboard

5. Look for "metrics/f1_score" chart

6. Should see F1 score updating every epoch!

7. After training, check:
   Validation Results:
     mAP50: 0.7000
     mAP50-95: 0.5000
     Precision: 0.8000
     Recall: 0.7500
     F1 Score: 0.7742  â† Now shown!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ QUICK REFERENCE

MOST IMPORTANT METRICS:
  1. mAP50 - Overall detection quality
  2. F1 Score - Balanced precision/recall
  3. Precision - Accuracy of detections
  4. Recall - Coverage of all objects

WHERE TO FIND THEM:
  â€¢ During training: Wandb dashboard (live)
  â€¢ After training: Terminal output + Wandb
  â€¢ Comparison: Wandb workspace (multiple runs)

TARGET VALUES (Wildlife Detection):
  mAP50:    > 0.65 (good), > 0.75 (excellent)
  F1 Score: > 0.65 (good), > 0.75 (excellent)
  Precision: > 0.70 (good), > 0.85 (excellent)
  Recall:   > 0.65 (good), > 0.80 (excellent)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“š MORE INFORMATION

For Wandb basics:
  â†’ See: WANDB_METRICS_GUIDE.md

For quick reference:
  â†’ See: WANDB_QUICK_REFERENCE.txt

For general training:
  â†’ See: COMPLETE_SETUP_GUIDE.md

For Wandb documentation:
  â†’ https://docs.wandb.ai/

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Status: âœ… F1 Score Logging Implemented
Last Updated: 2025-11-20
Version: 2.3

Happy monitoring! ğŸ“ŠğŸ“ˆğŸ¯

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

