â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          âœ¨ NEW FEATURE: F1 Score in Wandb Charts                    â•‘
â•‘              Automatic Logging Every Epoch + Test Set                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DATE: 2025-11-20
VERSION: 2.3
STATUS: âœ… Ready to Use

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ‰ WHAT'S NEW?

F1 Score is now automatically calculated and logged to Wandb!

âœ… Logged every epoch during training
âœ… Logged at the end on test set
âœ… Displayed in terminal output
âœ… Visible in Wandb charts
âœ… Includes per-class metrics

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š WHAT IS F1 SCORE?

F1 Score is the harmonic mean of Precision and Recall:

  F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)

WHY IT MATTERS:
  â€¢ Balances Precision (accuracy) and Recall (coverage)
  â€¢ Single metric for overall performance
  â€¢ Useful when you care about both false positives and false negatives
  â€¢ Common standard in machine learning competitions

EXAMPLE:
  Precision = 0.80 (80% of detections are correct)
  Recall    = 0.75 (found 75% of all animals)
  F1 Score  = 0.77 (good balance!)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ HOW IT WORKS

DURING TRAINING (Every Epoch):
  1. YOLO logs Precision and Recall to Wandb
  2. Custom callback calculates F1 Score
  3. F1 Score logged to Wandb automatically
  4. Appears in "metrics/f1_score" chart

AFTER TRAINING (Test Set):
  1. Model validation runs on test set
  2. F1 Score calculated from test results
  3. Logged to "test/f1_score"
  4. Displayed in terminal output

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’» WHAT YOU'LL SEE

DURING TRAINING:
  Starting training...
  âœ“ Custom F1 score logging callback added
  
  Epoch 1: ...
  Epoch 2: ...
  ... (F1 score logged every epoch to Wandb)

AFTER TRAINING:
  Validation Results:
    mAP50: 0.7000
    mAP50-95: 0.5000
    Precision: 0.8000
    Recall: 0.7500
    F1 Score: 0.7742  â† NEW! Now displayed!
  
  âœ“ Test metrics logged to Wandb

IN WANDB DASHBOARD:
  â€¢ "metrics/f1_score" chart (training)
  â€¢ "test/f1_score" metric (final test)
  â€¢ Per-class mAP50 metrics (all 6 species)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ˆ WHERE TO FIND F1 SCORE

1. WANDB DASHBOARD (Live during training):
   â€¢ Open Wandb URL (printed at start of training)
   â€¢ Go to "Charts" tab
   â€¢ Look for chart: "metrics/f1_score"
   â€¢ Updates every epoch!
   â€¢ Create custom chart to compare with mAP50, Precision, Recall

2. TERMINAL OUTPUT (After training):
   Validation Results:
     mAP50: 0.7000
     Precision: 0.8000
     Recall: 0.7500
     F1 Score: 0.7742  â† Here!

3. WANDB SUMMARY (After training):
   â€¢ Go to run page
   â€¢ Click "Overview" tab
   â€¢ Scroll to "Summary" section
   â€¢ See "test/f1_score: 0.7742"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”§ IMPLEMENTATION DETAILS

Added callback function:
  def on_fit_epoch_end(trainer):
      # Calculate F1 from precision and recall
      precision = metrics['metrics/precision(B)']
      recall = metrics['metrics/recall(B)']
      f1_score = 2 * (precision * recall) / (precision + recall)
      
      # Log to Wandb
      wandb.log({'metrics/f1_score': f1_score})

Registered callback:
  model.add_callback("on_fit_epoch_end", on_fit_epoch_end)

Updated validation:
  # Calculate F1 from test results
  f1_score = 2 * (precision * recall) / (precision + recall)
  
  # Display in terminal
  print(f"  F1 Score: {f1_score:.4f}")
  
  # Log to Wandb
  wandb.log({'test/f1_score': f1_score})

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š ALL METRICS NOW LOGGED

PERFORMANCE (During training - every epoch):
  âœ… metrics/mAP50           - Mean Average Precision @ 0.5
  âœ… metrics/mAP50-95         - Mean Average Precision @ 0.5:0.95
  âœ… metrics/precision        - Precision
  âœ… metrics/recall           - Recall
  âœ… metrics/f1_score         - F1 Score (NEW!)

TEST RESULTS (After training):
  âœ… test/mAP50               - Test set mAP50
  âœ… test/mAP50-95            - Test set mAP50-95
  âœ… test/precision           - Test set Precision
  âœ… test/recall              - Test set Recall
  âœ… test/f1_score            - Test set F1 Score (NEW!)

PER-CLASS (After training):
  âœ… test/Buffalo_mAP50       - Buffalo mAP50 (NEW!)
  âœ… test/Elephant_mAP50      - Elephant mAP50 (NEW!)
  âœ… test/Kudu_mAP50          - Kudu mAP50 (NEW!)
  âœ… test/Topi_mAP50          - Topi mAP50 (NEW!)
  âœ… test/Warthog_mAP50       - Warthog mAP50 (NEW!)
  âœ… test/Waterbuck_mAP50     - Waterbuck mAP50 (NEW!)

LOSSES:
  âœ… train/box_loss, train/cls_loss, train/dfl_loss
  âœ… val/box_loss, val/cls_loss, val/dfl_loss

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ TARGET VALUES

FOR WILDLIFE DETECTION:

mAP50:
  â€¢ > 0.50: Acceptable
  â€¢ > 0.65: Good
  â€¢ > 0.75: Excellent
  â€¢ > 0.85: Outstanding

F1 Score:
  â€¢ > 0.50: Acceptable
  â€¢ > 0.65: Good
  â€¢ > 0.75: Excellent
  â€¢ > 0.85: Outstanding

Precision:
  â€¢ > 0.60: Acceptable
  â€¢ > 0.70: Good
  â€¢ > 0.85: Excellent

Recall:
  â€¢ > 0.50: Acceptable
  â€¢ > 0.65: Good
  â€¢ > 0.80: Excellent

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ˆ EXAMPLE PROGRESSION

Epoch 1:
  mAP50:     0.15
  Precision: 0.30
  Recall:    0.20
  F1 Score:  0.24 â† Low, just starting

Epoch 10:
  mAP50:     0.45
  Precision: 0.60
  Recall:    0.50
  F1 Score:  0.55 â† Improving

Epoch 25:
  mAP50:     0.62
  Precision: 0.75
  Recall:    0.68
  F1 Score:  0.71 â† Good!

Epoch 50:
  mAP50:     0.70
  Precision: 0.82
  Recall:    0.75
  F1 Score:  0.78 â† Excellent!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… USAGE

No changes needed! Just train normally:

python train_vm.py --epochs 50 --batch 4

You'll automatically get:
  âœ… F1 score logged every epoch
  âœ… F1 score displayed after training
  âœ… F1 score in Wandb charts
  âœ… Per-class metrics

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ” VERIFICATION

To verify it's working:

1. Start training:
   python train_vm.py --epochs 5

2. Check output shows:
   âœ“ Custom F1 score logging callback added

3. Wait for epoch 1 to complete

4. Open Wandb dashboard

5. Search for "f1" in search box

6. Should see "metrics/f1_score" chart!

7. After training completes:
   Validation Results:
     ...
     F1 Score: 0.XXXX  â† Should appear!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š CREATING CUSTOM CHARTS IN WANDB

F1 Score + Components:
  1. Go to Wandb dashboard
  2. Click "+ Add visualization"
  3. Select "Line Plot"
  4. X-axis: "epoch"
  5. Y-axes: 
     - "metrics/f1_score"
     - "metrics/precision"
     - "metrics/recall"
  6. Title: "F1 Score and Components"
  7. Save!

Performance Overview:
  1. "+ Add visualization"
  2. "Line Plot"
  3. X-axis: "epoch"
  4. Y-axes:
     - "metrics/mAP50"
     - "metrics/mAP50-95"
     - "metrics/f1_score"
  5. Title: "Performance Metrics"
  6. Save!

Per-Class Performance:
  1. "+ Add visualization"
  2. "Bar Chart"
  3. Y-axes: all test/*_mAP50 metrics
  4. Title: "Per-Species Performance"
  5. Save!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ INTERPRETING F1 SCORE

F1 = 0.78 with Precision=0.82, Recall=0.75:
  â€¢ Good balance!
  â€¢ Model finds 75% of animals
  â€¢ 82% of detections are correct
  â€¢ Balanced performance

F1 = 0.65 with Precision=0.90, Recall=0.50:
  â€¢ High precision, low recall
  â€¢ Very accurate but misses many animals
  â€¢ May need to lower confidence threshold

F1 = 0.65 with Precision=0.50, Recall=0.90:
  â€¢ Low precision, high recall
  â€¢ Finds most animals but many false positives
  â€¢ May need to increase confidence threshold

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ WHY F1 SCORE MATTERS

FOR WILDLIFE CONSERVATION:

Scenario 1: Counting animals for population studies
  â†’ Need high Recall (find all animals)
  â†’ F1 score helps balance this with accuracy

Scenario 2: Rare species detection
  â†’ Need high Precision (minimize false alarms)
  â†’ F1 score ensures we don't miss too many

Scenario 3: Automated monitoring
  â†’ Need balanced performance
  â†’ F1 score is perfect single metric

F1 Score gives you ONE number to track overall quality!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“š DOCUMENTATION

Created files:
  âœ… WANDB_COMPLETE_METRICS.txt  - Complete metrics guide
  âœ… QUICK_F1_SCORE_REF.txt      - Quick F1 reference
  âœ… NEW_FEATURE_F1_SCORE.txt    - This file

Updated files:
  âœ… train_vm.py                 - Added F1 logging
  âœ… Updated validation function
  âœ… Added custom callback

See also:
  â€¢ WANDB_METRICS_GUIDE.md - Original metrics guide
  â€¢ WANDB_QUICK_REFERENCE.txt - Quick Wandb reference
  â€¢ COMPLETE_SETUP_GUIDE.md - Full training guide

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ¨ FEATURE SUMMARY

â€¢ Added: F1 Score calculation and logging
â€¢ Location: Wandb charts + terminal output
â€¢ Frequency: Every epoch + final test
â€¢ Includes: Per-class mAP50 metrics
â€¢ Automatic: No code changes needed by user
â€¢ Documented: Comprehensive guides created
â€¢ Status: âœ… Ready to use immediately

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ‰ YOU ASKED, WE DELIVERED!

Your question: "How do we get metrics into wandb charts? I don't have any F1 score"

Our answer:
  âœ… F1 Score now automatically logged every epoch
  âœ… Shows in Wandb charts in real-time
  âœ… Displayed in terminal output
  âœ… Includes per-class metrics
  âœ… Comprehensive documentation created

Happy monitoring! ğŸ“ŠğŸ“ˆğŸ¯

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Last Updated: 2025-11-20
Version: 2.3
Status: Production Ready âœ…

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

