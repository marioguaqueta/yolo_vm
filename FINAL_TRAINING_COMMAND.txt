â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              ğŸš€ FINAL TRAINING COMMAND - PRODUCTION READY             â•‘
â•‘            Complete Command with All Optimizations                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ¨ Complete training command with custom weights, augmentation, and optimization!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ RECOMMENDED PRODUCTION COMMAND

cd /home/estudiante/grupo_12/subsaharian_dataset/yolo_vm
conda activate yolov11-wildlife

python train_vm.py \
  --weights runs/yolov11_wildlife/weights/best.pt \
  --epochs 50 \
  --batch 4 \
  --imgsz 2048 \
  --rotate 15.0 \
  --scale 0.7 \
  --translate 0.15 \
  --fliplr 0.6 \
  --hsv-s 0.8 \
  --hsv-v 0.5 \
  --mosaic 1.0

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ PARAMETER BREAKDOWN

--weights runs/yolov11_wildlife/weights/best.pt
   â†’ Use your best model from previous training
   â†’ Fine-tuning from proven checkpoint
   â†’ Faster convergence

--epochs 50
   â†’ Sufficient for fine-tuning (30-50 typical)
   â†’ Use more (100) if training from scratch
   â†’ Early stopping prevents overfitting

--batch 4
   â†’ Optimal for 2048px images on L40 GPU (24GB)
   â†’ Reduce to 2 if you get OOM errors
   â†’ Increase to 8 if using smaller images (1024px)

--imgsz 2048
   â†’ High resolution for aerial detection
   â†’ Captures small/distant animals
   â†’ Good balance of quality vs speed

--rotate 15.0
   â†’ Rotates images Â±15 degrees
   â†’ Handles different drone orientations
   â†’ Conservative (not too extreme for aerial)

--scale 0.7
   â†’ Up to 70% zoom variation
   â†’ Simulates different altitudes
   â†’ Helps with distance variation

--translate 0.15
   â†’ Shifts images up to 15%
   â†’ Handles off-center subjects
   â†’ More than default 10%

--fliplr 0.6
   â†’ 60% chance horizontal flip
   â†’ Left/right symmetry
   â†’ Slightly more than default 50%

--hsv-s 0.8
   â†’ 80% saturation variation
   â†’ Handles lighting changes
   â†’ More than default 70%

--hsv-v 0.5
   â†’ 50% brightness variation
   â†’ Different times of day
   â†’ More than default 40%

--mosaic 1.0
   â†’ Always apply mosaic augmentation
   â†’ Combines 4 images
   â†’ Excellent for learning context

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ ALTERNATIVE SCENARIOS

SCENARIO 1: First Time Training (No Previous Weights)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python train_vm.py \
  --epochs 100 \
  --batch 4 \
  --imgsz 2048 \
  --rotate 15.0 \
  --scale 0.7 \
  --translate 0.15 \
  --fliplr 0.6 \
  --hsv-s 0.8 \
  --mosaic 1.0

Notes:
  â€¢ No --weights (starts from yolo11s.pt base)
  â€¢ More epochs (100) for training from scratch
  â€¢ All augmentation parameters included

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCENARIO 2: Fine-Tuning from Previous Best Model (RECOMMENDED)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python train_vm.py \
  --weights runs/yolov11_wildlife/weights/best.pt \
  --epochs 50 \
  --batch 4 \
  --imgsz 2048 \
  --rotate 15.0 \
  --scale 0.7 \
  --translate 0.15 \
  --fliplr 0.6 \
  --hsv-s 0.8 \
  --hsv-v 0.5

Notes:
  â€¢ Uses your best.pt from previous training
  â€¢ Fewer epochs (50) since starting from trained model
  â€¢ Aggressive augmentation for final improvements

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCENARIO 3: Maximum Augmentation (Small Dataset)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python train_vm.py \
  --weights runs/yolov11_wildlife/weights/best.pt \
  --epochs 60 \
  --batch 4 \
  --imgsz 2048 \
  --rotate 30.0 \
  --scale 0.9 \
  --translate 0.2 \
  --fliplr 0.7 \
  --hsv-h 0.05 \
  --hsv-s 0.9 \
  --hsv-v 0.6 \
  --mosaic 1.0

Notes:
  â€¢ Aggressive augmentation
  â€¢ 30Â° rotation (max for aerial)
  â€¢ 90% scale variation
  â€¢ Use if dataset is small (<500 images)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCENARIO 4: Conservative Augmentation (Large Dataset)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python train_vm.py \
  --weights runs/yolov11_wildlife/weights/best.pt \
  --epochs 40 \
  --batch 4 \
  --imgsz 2048 \
  --rotate 10.0 \
  --scale 0.5 \
  --translate 0.1 \
  --fliplr 0.5

Notes:
  â€¢ Minimal augmentation
  â€¢ Preserve original data characteristics
  â€¢ Use if dataset is large (>2000 images)
  â€¢ Faster training

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCENARIO 5: Memory-Optimized (If GPU OOM Issues)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python train_vm.py \
  --weights runs/yolov11_wildlife/weights/best.pt \
  --epochs 50 \
  --batch 2 \
  --imgsz 1024 \
  --rotate 15.0 \
  --scale 0.7 \
  --fliplr 0.6

Notes:
  â€¢ Smaller batch (2 instead of 4)
  â€¢ Smaller images (1024 instead of 2048)
  â€¢ Reduced GPU memory usage
  â€¢ Slightly faster training

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCENARIO 6: Quick Experiment (Test Settings)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python train_vm.py \
  --weights runs/yolov11_wildlife/weights/best.pt \
  --epochs 10 \
  --batch 4 \
  --imgsz 2048 \
  --rotate 15.0 \
  --scale 0.7 \
  --no-wandb

Notes:
  â€¢ Only 10 epochs (quick test)
  â€¢ No wandb (faster)
  â€¢ Use to test hyperparameters

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SCENARIO 7: Different Starting Model (Medium Size)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python train_vm.py \
  --epochs 80 \
  --batch 3 \
  --imgsz 2048 \
  --rotate 15.0 \
  --scale 0.7 \
  --translate 0.15 \
  --fliplr 0.6

# Note: Manually change MODEL in Config class to "yolo11m.pt"
# Medium model: Better accuracy, slower training

Notes:
  â€¢ Larger model (modify config first)
  â€¢ Smaller batch (3) due to model size
  â€¢ More epochs (80) for larger model

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ COMPLETE PRODUCTION COMMAND (COPY & PASTE)

For continuing from your best checkpoint with optimal augmentation:

cd /home/estudiante/grupo_12/subsaharian_dataset/yolo_vm && \
conda activate yolov11-wildlife && \
python train_vm.py \
  --weights runs/yolov11_wildlife/weights/best.pt \
  --epochs 50 \
  --batch 4 \
  --imgsz 2048 \
  --rotate 15.0 \
  --scale 0.7 \
  --translate 0.15 \
  --fliplr 0.6 \
  --hsv-s 0.8 \
  --hsv-v 0.5 \
  --mosaic 1.0

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”¥ WITH WANDB API KEY (Automated)

If you want to pass Wandb key directly:

python train_vm.py \
  --weights runs/yolov11_wildlife/weights/best.pt \
  --epochs 50 \
  --batch 4 \
  --imgsz 2048 \
  --rotate 15.0 \
  --scale 0.7 \
  --translate 0.15 \
  --fliplr 0.6 \
  --hsv-s 0.8 \
  --hsv-v 0.5 \
  --mosaic 1.0 \
  --wandb-key YOUR_WANDB_API_KEY_HERE

Get your key from: https://wandb.ai/authorize

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’» BACKGROUND TRAINING (Long Sessions)

For training that takes hours, run in background:

nohup python train_vm.py \
  --weights runs/yolov11_wildlife/weights/best.pt \
  --epochs 50 \
  --batch 4 \
  --imgsz 2048 \
  --rotate 15.0 \
  --scale 0.7 \
  --translate 0.15 \
  --fliplr 0.6 \
  --hsv-s 0.8 \
  --hsv-v 0.5 \
  --mosaic 1.0 \
  > training.log 2>&1 &

# View progress:
tail -f training.log

# Check if still running:
ps aux | grep train_vm.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š EXPECTED RESULTS

With these settings, you should achieve:

From Scratch (100 epochs):
  â€¢ mAP50: 0.65-0.75
  â€¢ F1 Score: 0.65-0.75
  â€¢ Training time: ~8-10 hours

Fine-Tuning (50 epochs):
  â€¢ mAP50: 0.70-0.80
  â€¢ F1 Score: 0.70-0.80
  â€¢ Training time: ~4-5 hours

Aggressive Aug (60 epochs):
  â€¢ mAP50: 0.68-0.78
  â€¢ F1 Score: 0.68-0.78
  â€¢ Better generalization
  â€¢ Training time: ~5-6 hours

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… PRE-FLIGHT CHECKLIST

Before running, verify:

â–¡ Environment activated: conda activate yolov11-wildlife
â–¡ In correct directory: cd .../yolo_vm
â–¡ Dataset prepared:
  - ls ../general_dataset/images/train/*.JPG | wc -l â†’ 928
  - ls ../general_dataset/labels/train/*.txt | wc -l â†’ 928
â–¡ Previous model exists (if using --weights):
  - ls runs/yolov11_wildlife/weights/best.pt
â–¡ GPU available: nvidia-smi
â–¡ Disk space: df -h (> 10GB free)
â–¡ Wandb logged in: wandb login (or use --wandb-key)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ PARAMETER SELECTION GUIDE

HOW TO CHOOSE VALUES:

Epochs:
  â€¢ From scratch: 80-100
  â€¢ Fine-tuning: 30-50
  â€¢ Quick test: 5-10

Batch Size:
  â€¢ 2048px images + 24GB GPU: 4
  â€¢ 1024px images + 24GB GPU: 8
  â€¢ OOM errors: reduce by half

Image Size:
  â€¢ High accuracy: 2048
  â€¢ Balanced: 1024
  â€¢ Fast inference: 640

Rotation:
  â€¢ Aerial (drone stable): 10-15Â°
  â€¢ Aerial (various angles): 20-30Â°
  â€¢ Ground-level: 0Â° or 45Â°

Scale:
  â€¢ Conservative: 0.3-0.5
  â€¢ Moderate: 0.6-0.7
  â€¢ Aggressive: 0.8-0.9

Translation:
  â€¢ Conservative: 0.1
  â€¢ Moderate: 0.15-0.2
  â€¢ Aggressive: 0.25

Horizontal Flip:
  â€¢ Wildlife/Aerial: 0.5-0.7
  â€¢ Text/Faces: 0.0
  â€¢ General: 0.5

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ PRO TIPS

1. Start with Recommended Command
   â†’ Use the production command at the top
   â†’ Adjust based on results

2. Monitor First Epoch
   â†’ Watch GPU memory usage
   â†’ Check augmentation settings display
   â†’ Verify F1 score logging

3. Use Wandb for Comparison
   â†’ Run multiple experiments
   â†’ Compare F1 scores
   â†’ Find optimal settings

4. Save Good Checkpoints
   â†’ Copy best.pt to safe location
   â†’ Rename with descriptive name:
     best_50epochs_rotate15_scale07.pt

5. Document Your Experiments
   â†’ Keep notes on what worked
   â†’ Track hyperparameters
   â†’ Use Wandb tags

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ TROUBLESHOOTING

ISSUE: CUDA out of memory
FIX: Reduce --batch 2 or --imgsz 1024

ISSUE: Training too slow
FIX: Reduce --imgsz 1024 or --batch 2

ISSUE: mAP not improving
FIX: Increase --epochs or adjust augmentation

ISSUE: Overfitting (val loss increases)
FIX: Increase augmentation (more --rotate, --scale)

ISSUE: Underfitting (both losses high)
FIX: More --epochs or reduce augmentation

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ˆ MONITORING CHECKLIST

During Training:
â–¡ Wandb dashboard shows metrics updating
â–¡ F1 score appears after epoch 1
â–¡ Losses decreasing
â–¡ GPU at 80-95% utilization
â–¡ No OOM errors

After Training:
â–¡ mAP50 > 0.65 (good), > 0.75 (excellent)
â–¡ F1 Score > 0.65 (good), > 0.75 (excellent)
â–¡ Precision and Recall balanced
â–¡ Per-class metrics reasonable
â–¡ best.pt saved successfully

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ LEARNING PROGRESSION

Week 1: Baseline
  python train_vm.py --epochs 50
  â†’ Establish baseline (no augmentation)

Week 2: Add Augmentation
  python train_vm.py --epochs 50 --rotate 15.0 --scale 0.7
  â†’ See augmentation impact

Week 3: Fine-Tune
  python train_vm.py --weights best.pt --epochs 30 --rotate 15.0 --scale 0.7
  â†’ Build on previous results

Week 4: Optimize
  python train_vm.py --weights best.pt --epochs 50 --rotate 20.0 --scale 0.8
  â†’ Find optimal settings

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ¨ FINAL RECOMMENDED COMMAND (BEST FOR YOUR USE CASE)

For Wildlife Aerial Detection with Fine-Tuning:

python train_vm.py \
  --weights runs/yolov11_wildlife/weights/best.pt \
  --epochs 50 \
  --batch 4 \
  --imgsz 2048 \
  --rotate 15.0 \
  --scale 0.7 \
  --translate 0.15 \
  --fliplr 0.6 \
  --hsv-s 0.8 \
  --hsv-v 0.5 \
  --mosaic 1.0

This command:
  âœ… Uses your best previous model
  âœ… Optimal rotation for aerial (15Â°)
  âœ… Good zoom variation (70%)
  âœ… Enhanced translation (15%)
  âœ… Balanced flipping (60%)
  âœ… Strong color augmentation
  âœ… Mosaic for context learning
  âœ… All labels auto-transformed
  âœ… F1 score logged automatically

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ‰ YOU'RE READY TO TRAIN!

Copy the command above, paste in your terminal, and start training!

Monitor progress:
  â€¢ Wandb dashboard: Real-time metrics
  â€¢ Terminal: Progress bars
  â€¢ GPU: nvidia-smi

Expected time: ~4-5 hours for 50 epochs

Good luck! ğŸš€ğŸ¦ğŸ˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Status: âœ… Production Ready
Last Updated: 2025-11-20
Version: 2.3 (Complete)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

